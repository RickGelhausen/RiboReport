# RiboReport19
This repository contains all code to recreate the contents of "RiboReport19 - Benchmarking ribosome profiling based identification of open reading frames in bacteria. Following are descriptions of the required steps.

| WARNING: This documentation will be updated as soon as the SRA upload of the sequencing data is finished! |
| --- |

## Processing of High Throughput Sequencing Data
In the publication, the data required for the generation of our result figures was created using the `snakemake` workflow described below. After the creation of the input data, the figures from the publication were generated by using the evaluation scripts provided in the evaluation folder.
The generation and usage of the final tables and figures is described below.

## Generation of the Dataset

### Dependencies
- miniconda3
- snakemake =5.4.5

### Input data
For running the workflow, several input files are required:
- genome.fa (in the data folder)
- annotation.gtf (in the data folder)
- fastq files and bigwig files available via NCBI GEO (https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE131514, token:ofkbusuqzbcvfip)

### Workflow
---
**Note**
Even though `snakemake` workflows are executable locally, we do not advise this due to high memory usage and runtime of some of the processing steps. We ran the workflow on a TORQUE cluster system and provide according configuration files for TORQUE and SGE.

---

To run the provided `snakemake` workflow, follow the instructions below:

#### 1. Setup the workflow folder and download the workflow:

~~~~
mkdir benchmark; cd benchmark;
git clone git@github.com:RickGelhausen/ribo_benchmark.git
~~~~

#### 2. Required tools
In order to run the workflow, the tools analysed in the publication have to be installed.
Reparation and Ribotish are automatically downloaded from bioconda and do not need any prior installation.
IRSOM and DeepRibo are not on conda and have to be installed manually.

First of all, create a `tools` folder in the benchmark repository.

~~~~
mkdir tools; cd tools;
~~~~

Next, we install irsom. To make it compatible with our workflow, we first create a conda environment for the dependencies:

~~~~
conda create -n irsom -c bioconda -c conda-forge plotnine pandas numpy tensorflow matplotlib docopt
conda activate irsom
~~~~

Then, we download and install irsom:

~~~~
git clone https://forge.ibisc.univ-evry.fr/lplaton/IRSOM.git
pip install -r IRSOM/pip_package.txt
~~~~

This should only install irsom, as the other dependencies are already installed in the conda environment.

~~~~
conda activate irsom
~~~~

This leaves the installation of DeepRibo. For DeepRibo all dependencies will be downloaded automatically by the workflow.
We just have to download DeepRibo itself.

~~~~
git clone git@github.com:Biobix/DeepRibo.git
~~~~

Unfortunately, DeepRibo did not work out-of-the-box for us. In order to get it working, we had to do two changes to their prediction script.
To apply these changes, we provided a `deepribo-patch.sh` in the script folder. Just navigate to the script folder and execute the file.

~~~~
cd ../ribo_benchmark/scripts;
bash deepribo-patch.sh;
cd ../../
~~~~

#### 3. Fetch the annotation and genome files:

~~~~
cp ribo_benchmark/data/annotation.zip . ;
unzip annotation.zip;
cp ribo_benchmark/data/genome.zip . ;
unzip genome.zip;
~~~~

#### 4. Retrieve the sequencing data:
---
**Note**
This section will be updated as soon as the data SRA data is available.

---

<!---There are many ways to download fastq files with SRA. For more information about downloading please have a look at the following guide: [Downloading SRA data using command line utilities](https://www.ncbi.nlm.nih.gov/books/NBK158899/). --->

<!--- The simplest way is most likely the usage of the [SRA Toolkit](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc&f=std), as it allows direct conversion into `.fastq` files. --->

<!--- Using the `SRA Toolkit` and the `SRR IDs` for our 3 samples we can use the `fasterq-dump` executable to download the according `.fastq` files. --->

<!--- If you do not have the `SRA Toolkit`, we suggest using the conda environment: --->

<!--- ~~~~ --->
<!--- conda create -n sra-tools -c bioconda -c conda-forge sra-tools --->
<!--- conda activate sra-tools --->
<!--- ~~~~ --->
<!--- (use source activate, if conda is not set-up for your bash) --->

<!--- Then you can use the following commands to generate the required `.fastq` files. --->

<!--- ~~~~ --->
<!--- fasterq-dump SRR; gzip SRR .fastq; --->
<!--- fasterq-dump SRR; gzip SRR .fastq; --->
<!--- fasterq-dump SRR; gzip SRR .fastq; --->
<!--- fasterq-dump SRR; gzip SRR .fastq; --->
<!--- ~~~~ --->

<!--- Afterwards, you can deactivate your conda environment. --->
<!--- ~~~~ --->
<!--- conda deactivate sra-tools --->
<!--- ~~~~ --->

#### 5. Run the snakemake workflow:

In order to run `snakemake`, the creation of a conda environment is required. First install [miniconda3](https://docs.conda.io/en/latest/miniconda.html).

Once miniconda3 is installed. Create a snakemake environment:
~~~~
conda create -n snakemake -c conda-forge -c bioconda snakemake
conda activate snakemake
~~~~

Then you can copy and complete one of the provided submission scripts, or create your own.
~~~~
cp ribo_benchmark/torque.sh .
~~~~
or
~~~~
cp ribo_benchmark/sge.sh .
~~~~

Example for torque.sh:

~~~~
#!/bin/bash
#PBS -N benchmark
#PBS -S /bin/bash
#PBS -q "long"
#PBS -d <file path>/benchmark
#PBS -l nodes=1:ppn=1
#PBS -o <file path>/benchmark
#PBS -j oe
cd <file path>/benchmark
export PATH="<file path>/miniconda3/bin/:$PATH"
source activate snakemake
snakemake --latency-wait 600 --use-conda -s ribo_benchmark/Snakefile --configfile ribo_benchmark/config.yaml --directory ${PWD} -j 20 --cluster-config ribo_benchmark/torque.yaml --cluster "qsub -N {cluster.jobname} -S /bin/bash -q {cluster.qname} -d <file path>/benchmark -l {cluster.resources} -o {cluster.logoutputdir} -j oe"
~~~~

All **file path** statements have to be replaced by the path to your benchmark folder.

**Please note** that these scripts might need some extra changes depending on your cluster system. If your cluster system does not run SGE or TORQUE, these files will most likely not work at all. In the case they run one SGE or TORQUE, there might be slightly different definitions for the resource statements (here `#PBS -l nodes=1:ppn=1`). This is then also the case for the configuration files `sge.yaml` and `torque.yaml`.


## Visualisation and plotting of the Results
All data can be visualised using the following scripts inside the evaluation folder. Further, an `evaluation_call.sh` script, containing all calls for the plotting pipeline, is provided. This bash script only works if all python scripts are positioned in the same folder and the input gtf-files from the data folder are stored in a "data"-folder in the same location.

### Dependencies
- numpy =1.16.3
- matplotlib =3.0.3
- seaborn =0.9.0
- pandas =0.24.2
- simple_venn =0.1.0
- bedtools =v2.28.0

### statistics.py

Parameters:
- reference_data (-r) path to the .gtf file containing all genes of the investigated genome or the investigated subset of genes
- tool_data (-t) path to gtf file containing all predictions for the tools: deepribo, ribotish, reparation and irsom
- save_path (-o) path to a directory, where the result tables will be stored
- overlap_cutoff (-c) allowed sequence overlap cutoff between gene and prediction

Output:
- df_stat.csv -> main result table storing all computed statistical measurements
- df_venn_FN_gene_dict.csv -> table containing a column for each tool listing the number of genes counted as false negatives (FN)
- df_venn_FP_predictions_dict.csv -> table containing a column for each tool listing the number of genes counted as false positive (FP)
- df_venn_predictions.csv -> table containing a column for each tool listing the number of genes counted as suboptimal predictions
- df_venn_genes.csv -> table containing a column for each tool listing the number of genes counted as true positive (TP)

This script generates several statistical measurements for a reference and tool prediction .gtf file. First true positives (TP), false positives (FP) and false negatives (FN) are predicted. One prediction will be associated with one gene and counted as one true positve. The association selection is based on the lowest p-value (0.05). All genes fulfilling the overlap cutoff will be counted as suboptimals and not as false positives. False positives are all predictions, where no gene fulfilling the overlap cutoff could be found and the false negatives vice versa. Based on this computations the recall, FNR, precision, FDR and F1 measure are calculated.

### plot_barplots.py
Parameters:
- input1_df (-i1) df_stat.csv of the statistics.py script for the first overlap cutoff
- input2_df (-i2) df_stat.csv of the statistics.py script for the second overlap cutoff
- save_path (-o) path to directory where the plots will be stored

Output:
- bar_FNR.pdf -> barplot of FNR measures for different tools and two cutoff conditions
- bar_recall.pdf -> barplot of recall measures for different tools and two cutoff conditions
- bar_precision.pdf -> barplot of precision measures for different tools and two cutoff conditions
- bar_FDR.pdf -> barplot of FDR measures for different tools and two cutoff conditions
- bar_F1.pdf -> barplot of F1 measures for different tools and two cutoff conditions

This script generates barplots of statistical measures for the different tools and two overlap cutoff conditions. The output barplots consist of FNR, recall, precision, FDR and F1 measures. It is based on the statistics.py statistical output table.

### venn_diagram.py
Parameters:
- input_df (-i) .cvs containing the list of true positive genes for the used tools
- save_path (-o) path where the Venn diagramm will be saved
- name_folder (-n) name of the result folder of the investigated set. It will be used in the file name to make it unique.
- coverage_percent (-c) percentage of overlap cutoff that was used to determine the true positves. It will be used in the file name to make it unique

Output:
- venn_diagram.pdf -> a 4 Venn diagram highlighting overlapping predictions of the tool. 

This script will generate a 4 Venn diagram for the overlap of true positive predicted genes of the 4 investigated tools. 
